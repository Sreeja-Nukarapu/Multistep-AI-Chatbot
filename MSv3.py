import os
import re
import requests
import cohere
import matplotlib.pyplot as plt
from tavily import TavilyClient
import gradio as gr
import io
from io import BytesIO
from PIL import Image
import base64

# ----------------- Backend Functions -----------------

def tavily_search(query):
    """
    Calls the Tavily API to search the web.
    """
    tavily_client = TavilyClient(api_key="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")
    response = tavily_client.search(query, max_results=1, include_answer='advanced', include_images='True')
    return response

def cohere_play(search_results, query):
    """
    Uses the Cohere API to generate Python code for visualizing the search results.
    """
    co = cohere.ClientV2(api_key="Bf6NnGGkOVsK2ut7gfzCc0ySnLCalz0oCTyD4roa")
    prompt = (
        f"Using the following search data: {search_results}, write Python code that visualizes in form of Word Association Networks"
        f"the results as per the user query: '{query}'. The code should be self-contained and executable. "
        "Wrap the code in triple backticks with 'python' as the language."
    )
    res = co.chat(
        model="command-r-plus-08-2024",
        messages=[
            {"role": "user", "content": prompt}
        ],
    )
    return res

def extract_code(text):
    """
    Extracts code wrapped in a markdown python code block.
    """
    code_match = re.search(r'```python(.*?)```', text, re.DOTALL)
    if code_match:
        return code_match.group(1).strip()
    return None

def response(query):
    """
    Orchestrates the multi-step process:
      - Uses Tavily API to fetch search details.
      - Calls the Cohere API to generate visualization code.
    
    The query is modified to request detailed and conclusive information without data shortage disclaimers.
    """
    query1 = (
        f"Provide detailed and conclusive information about {query} based on historical trends. "
        "If data is limited, make a best-effort speculative analysis without mentioning any data shortages or disclaimers."
    )
    print("Performing web search using Tavily API...")
    try:
        search_results = tavily_search(query1)
    except Exception as error:
        return f"Error in Tavily search: {error}", None
    print("Performing code generation using Cohere API...")
    try:
        res = cohere_play(search_results, query)
    except Exception as error:
        return f"Error in Cohere API: {error}", None
    return search_results, res

def execute_generated_code(code_str):
    """
    Executes the dynamically generated Python code and captures the resulting plot as a PIL image.
    Overrides plt.show() to prevent blocking the interface.
    """
    original_show = plt.show
    plt.show = lambda: None

    local_env = {}
    try:
        exec(code_str, local_env)
        fig = plt.gcf()
        buf = io.BytesIO()
        fig.savefig(buf, format='png', dpi=50)
        buf.seek(0)
        plt.close(fig)
        image = Image.open(buf)
        return image
    except Exception as e:
        return f"Error during code execution: {e}"
    finally:
        plt.show = original_show

def fetch_images_from_urls(search_results):
    """
    Extracts image URLs from the Tavily search results and fetches them.
    Returns a list of PIL Images.
    """
    print("Generating Image list...")
    images_list = []
    if isinstance(search_results, dict) and "images" in search_results:
        image_urls = search_results["images"]
        if not isinstance(image_urls, list):
            image_urls = [image_urls]
        for url in image_urls[:3]:
            try:
                response_img = requests.get(url, timeout=5)
                img = Image.open(BytesIO(response_img.content))
                images_list.append(img)
            except Exception as e:
                print(f"Error fetching image from {url}: {e}")
    print("Task Complete")
    return images_list

def pil_to_base64(image):
    """
    Converts a PIL Image to a base64 encoded string for embedding in HTML.
    """
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
    return f"data:image/png;base64,{img_str}"

def chatbot(query):
    """
    Main chatbot function that returns:
      1. Tavily search results (text),
      2. The visualization image generated by executing Cohere code,
      3. A gallery (list) of images fetched from the search results.
    """
    search_results, res = response(query)
    print(search_results['answer'])
    code_text = res.message.content[0].text
    extracted_code = extract_code(code_text)

    vis_image = execute_generated_code(extracted_code)
    gallery_images = fetch_images_from_urls(search_results)
    return str(search_results['answer']), vis_image, gallery_images

# ----------------- Chatbot UI -----------------

def respond_chat(user_message, history):
    """
    Updates the conversation history with the new user query and bot response.
    The bot response is formatted as HTML with the text, visualization image, and a gallery of images.
    """
    # Call the backend chatbot function
    search_text, vis_image, gallery_images = chatbot(user_message)
    
    # Build the bot's response as HTML
    bot_message = f"<p><strong>Search Results:</strong><br>{search_text}</p>"
    
    if isinstance(vis_image, Image.Image):
        vis_img_data = pil_to_base64(vis_image)
        bot_message += f"<p><strong>Visualization:</strong><br><img src='{vis_img_data}' width='400'></p>"
    else:
        bot_message += f"<p><strong>Visualization:</strong><br>{vis_image}</p>"
    
    if gallery_images:
        bot_message += "<p><strong>Fetched Images:</strong><br>"
        for img in gallery_images:
            if isinstance(img, Image.Image):
                img_data = pil_to_base64(img)
                bot_message += f"<img src='{img_data}' width='150' style='margin: 5px;'>"
        bot_message += "</p>"
    
    # Append the new interaction to the existing history
    history = history + [[user_message, bot_message]]
    # Return the updated conversation history, updated state, and clear the textbox
    return history, history, ""

# Custom CSS for styling
custom_css = """
.custom_header {
    text-align: center;
    font-family: "Times New Roman", Times, serif;
    font-weight: bold;
    font-style: italic;
    font-size: 28px;
    margin-bottom: 20px;
}

.custom_footer {
    text-align: center;
    font-family: "Times New Roman", Times, serif;
    font-weight: bold;
    font-size: 12px;
    margin-bottom: 5px;
}
.chatbot .wrap {font-family: Arial, sans-serif; font-size: 14px; }
.gradio-container { background-color: #282828; }
"""

with gr.Blocks(css=custom_css, title="Multi-Step AI Agent Chatbot") as demo:
    gr.Markdown('<div class="custom_header">Multi-Step AI Agent Chatbot</div>')
    # Increase the height of the chat box by setting a height parameter.
    chatbot_ui = gr.Chatbot(elem_id="AI_chatbot", height=500)
    state = gr.State([])  # conversation history state
    with gr.Row():
        txt = gr.Textbox(
            show_label=False,
            placeholder="Type your message here and press Enter",
        )
    # Update the submit callback to return chatbot history, state, and clear the textbox
    txt.submit(respond_chat, [txt, state], [chatbot_ui, state, txt], show_progress=True)
    gr.Button("Clear Chat").click(lambda: ([], []), None, [chatbot_ui, state], queue=False)
    gr.Markdown('<div class="custom_footer">Powered by Tavily & Cohere ‚òÄÔ∏èüöÄ</div>')

demo.launch()